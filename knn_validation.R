install.packages("mlbench")
library(mlbench)
library(class);library(caret)
install.packages("sampling")
library(sampling); library(dplyr)
data(PimaIndiansDiabetes)
AvaData=PimaIndiansDiabetes
AvaData$diabetes=as.factor(AvaData$diabetes)
AvaDataX=AvaData[,-9]
AvaDataY=AvaData[, 9]

AvaData$diabetes=as.factor(AvaData$diabetes)
AvaN=nrow(AvaData)

#contrasts(AvaData$diabetes)
GN=round(table(AvaData$diabetes)*0.8,0)
set.seed(3)
Trainget=strata(AvaData,"diabetes",size=c(GN[[2]],GN[[1]]),method="srswor" )
TrainData=getdata(AvaData,Trainget)
TrainInx=TrainData$ID_unit
ValInx=c(1:AvaN)[-TrainInx]
TrainDataX=AvaDataX[TrainInx,]
TrainDataY=AvaDataY[TrainInx]
ValDataX=AvaDataX[ValInx,]
ValDataY=AvaDataY[ValInx]

#table(AvaData$diabetes)
#table(TrainDataY)
#table(ValDataY)

#暗F~1-100憨姚撤墙Tv
#]wtuning parameter (k=1,2,K,100)A氓Htraining set廿knnだ摸家
#Hvalidation setXAだONJパk=1,2,K,100睾cknn家AoY汗w代薄p铆p衡岿~v/非Tv

AccuracyAll=rep(1:100)
for(i in 1:100){
	PredY=knn(train=TrainDataX,test=ValDataX, cl=TrainDataY, k=i, prob=F)
	#AccuracyAll[i]=confusionMatrix(PredY, ValDataY) #e暴癀拷T岘暴窨~
	#AccuracyAll[i]=confusionMatrix(PredY, ValDataY)$overall
	AccuracyAll[i]=confusionMatrix(PredY, ValDataY)$overall["Accuracy"]
}

#匡程j非Tv тXvalidation error 程p(┪accuracy程j)k
OptimalK=which.max(AccuracyAll)

#e瓜
win.graph()
plot(c(1:100), AccuracyAll, pch=19, xlab="K", ylab="Validation Accuracy", type="b")


# H程Ak & available set 睾cknn model
#knn(train=AvaDataX,test=TestDataX, cl=AvaDataY, k=OptimalK, prob=F)

#沽刚[诡best k瑟confusion matrix and U贺非Tv
i=OptimalK
PredY=knn(train=TrainDataX,test=ValDataX, cl=TrainDataY, k=i, prob=F)
confusionMatrix(PredY, ValDataY)
win.graph()
plot.roc(as.numeric(ValDataY),as.numeric(PredY), print.auc=TRUE)


